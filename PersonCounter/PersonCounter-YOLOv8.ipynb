{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPiBf09L6FzR/0hRlgv0C53"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from ultralytics import YOLO, solutions\n","from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import cv2"],"metadata":{"id":"wcUuFREwMhd5","executionInfo":{"status":"ok","timestamp":1722506477570,"user_tz":-60,"elapsed":6866,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfCZLC9XMuq5","executionInfo":{"status":"ok","timestamp":1722506496785,"user_tz":-60,"elapsed":19217,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}},"outputId":"abc3a4af-963b-4e8a-c9b6-98ff46c22527"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["model = YOLO('yolov8n.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ji_utTnM-L-","executionInfo":{"status":"ok","timestamp":1722506498261,"user_tz":-60,"elapsed":1479,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}},"outputId":"055f5b6f-a026-4398-bd3b-e4ca8c29fa20"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 245MB/s]\n"]}]},{"cell_type":"code","source":["num_class = len(model.names)\n","num_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGrvCBGENKc8","executionInfo":{"status":"ok","timestamp":1722506498261,"user_tz":-60,"elapsed":3,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}},"outputId":"02c8888c-755a-48c0-8030-7e36e8530de2"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["80"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["video_path = '/content/gdrive/MyDrive/Projects/PeopleDetectioncounter/person_sample02.mp4'\n","video_cap = cv2.VideoCapture(video_path)\n","assert video_cap.isOpened(), \"Error loading video file\"\n","W, H, FPS = (int(video_cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n","output_path = '/content/gdrive/MyDrive/Projects/PeopleDetectioncounter/person_sample_output02.mp4'\n","output = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), FPS, (W,H))\n","\n","counter = solutions.ObjectCounter(view_img=True,\n","                                  names=model.names,\n","                                  reg_pts=[(20, 400), (int(W), 400)],\n","                                  draw_tracks=True,\n","                                  line_thickness=5)\n","while video_cap.isOpened():\n","  ret, frame = video_cap.read()\n","  if not ret:\n","    print('Video frame is empty')\n","    break\n","  tracks = model.track(frame, persist=True, show=False, classes=[0])\n","  frame = counter.start_counting(frame, tracks)\n","  output.write(frame)\n","video_cap.release()\n","output.release()\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTbbjOxSNLCz","executionInfo":{"status":"ok","timestamp":1722506547360,"user_tz":-60,"elapsed":49101,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}},"outputId":"f173bbcb-630a-4c50-e54f-8e0e5d4e8569"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n","\n","Line Counter Initiated.\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n","Collecting lapx>=0.5.2\n","  Downloading lapx-0.5.9.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.26.4)\n","Downloading lapx-0.5.9.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 87.2 MB/s eta 0:00:00\n","Installing collected packages: lapx\n","Successfully installed lapx-0.5.9.post1\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.1s, installed 1 package: ['lapx>=0.5.2']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","0: 384x640 10 persons, 120.1ms\n","Speed: 17.0ms preprocess, 120.1ms inference, 923.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 persons, 7.8ms\n","Speed: 3.3ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 9.9ms\n","Speed: 4.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 10.1ms\n","Speed: 4.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 persons, 8.2ms\n","Speed: 3.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 9.6ms\n","Speed: 3.8ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 persons, 10.7ms\n","Speed: 3.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 14 persons, 10.2ms\n","Speed: 3.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 persons, 9.1ms\n","Speed: 4.2ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 persons, 11.3ms\n","Speed: 3.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 12.2ms\n","Speed: 4.0ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 7.4ms\n","Speed: 4.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 7.2ms\n","Speed: 3.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 14.5ms\n","Speed: 3.4ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 18.1ms\n","Speed: 3.3ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 11.0ms\n","Speed: 3.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 9.4ms\n","Speed: 3.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 9.4ms\n","Speed: 3.5ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 9.8ms\n","Speed: 3.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 8.9ms\n","Speed: 3.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.1ms\n","Speed: 3.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 10.5ms\n","Speed: 3.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 12.1ms\n","Speed: 3.4ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.3ms\n","Speed: 3.2ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.7ms\n","Speed: 3.6ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.4ms\n","Speed: 3.3ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.9ms\n","Speed: 3.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 8.7ms\n","Speed: 3.9ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 7.4ms\n","Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 8.3ms\n","Speed: 3.3ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 11.8ms\n","Speed: 4.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 11.3ms\n","Speed: 2.9ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.0ms\n","Speed: 3.5ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 8.8ms\n","Speed: 3.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.0ms\n","Speed: 3.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 11.0ms\n","Speed: 3.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 8.9ms\n","Speed: 5.3ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 14.8ms\n","Speed: 3.2ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 18.7ms\n","Speed: 5.1ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 22.1ms\n","Speed: 9.2ms preprocess, 22.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 15.5ms\n","Speed: 3.2ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 8.8ms\n","Speed: 3.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 10.2ms\n","Speed: 2.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 10.8ms\n","Speed: 3.3ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 8.5ms\n","Speed: 3.5ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 14.7ms\n","Speed: 3.1ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 15.5ms\n","Speed: 6.3ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 8.9ms\n","Speed: 3.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 11.7ms\n","Speed: 3.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 10.9ms\n","Speed: 5.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 20.7ms\n","Speed: 3.9ms preprocess, 20.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 13.9ms\n","Speed: 3.6ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.0ms\n","Speed: 2.9ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 10.7ms\n","Speed: 11.3ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 15.7ms\n","Speed: 3.1ms preprocess, 15.7ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 11.5ms\n","Speed: 5.0ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 8.7ms\n","Speed: 9.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.1ms\n","Speed: 9.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.6ms\n","Speed: 9.7ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 10.6ms\n","Speed: 3.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.7ms\n","Speed: 3.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 16.4ms\n","Speed: 5.0ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.9ms\n","Speed: 3.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 13.0ms\n","Speed: 3.5ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 11.6ms\n","Speed: 5.4ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 16.9ms\n","Speed: 3.2ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 15.0ms\n","Speed: 3.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 8.0ms\n","Speed: 3.0ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.3ms\n","Speed: 2.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.4ms\n","Speed: 4.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 7.8ms\n","Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.1ms\n","Speed: 3.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.0ms\n","Speed: 3.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 12.9ms\n","Speed: 4.5ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 19.7ms\n","Speed: 4.5ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.1ms\n","Speed: 3.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.8ms\n","Speed: 10.7ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.2ms\n","Speed: 3.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 8.5ms\n","Speed: 3.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 7.9ms\n","Speed: 3.2ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.3ms\n","Speed: 3.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.5ms\n","Speed: 3.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 12.9ms\n","Speed: 3.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.6ms\n","Speed: 6.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 persons, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 persons, 10.6ms\n","Speed: 3.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 persons, 10.7ms\n","Speed: 3.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 persons, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 8.0ms\n","Speed: 9.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.0ms\n","Speed: 2.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.3ms\n","Speed: 2.9ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.2ms\n","Speed: 3.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.5ms\n","Speed: 3.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 16.9ms\n","Speed: 3.1ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 12.1ms\n","Speed: 11.7ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 16.5ms\n","Speed: 3.1ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 15.3ms\n","Speed: 3.0ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.6ms\n","Speed: 3.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.6ms\n","Speed: 3.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 10.1ms\n","Speed: 2.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 7.2ms\n","Speed: 3.4ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 14.4ms\n","Speed: 3.2ms preprocess, 14.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.9ms\n","Speed: 5.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.3ms\n","Speed: 3.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.7ms\n","Speed: 2.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.3ms\n","Speed: 3.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 12.9ms\n","Speed: 3.4ms preprocess, 12.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.5ms\n","Speed: 3.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.6ms\n","Speed: 3.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 10.4ms\n","Speed: 3.3ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 15.5ms\n","Speed: 4.1ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.0ms\n","Speed: 3.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.9ms\n","Speed: 3.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 11.4ms\n","Speed: 3.1ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.4ms\n","Speed: 3.2ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 30 persons, 9.8ms\n","Speed: 3.0ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 9.1ms\n","Speed: 3.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 7.2ms\n","Speed: 3.0ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 11.1ms\n","Speed: 4.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.7ms\n","Speed: 4.3ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.0ms\n","Speed: 3.2ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.3ms\n","Speed: 5.5ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.5ms\n","Speed: 3.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 7.2ms\n","Speed: 4.8ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.8ms\n","Speed: 3.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 11.4ms\n","Speed: 3.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 12.2ms\n","Speed: 3.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 7.3ms\n","Speed: 3.3ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 10.8ms\n","Speed: 3.1ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.2ms\n","Speed: 3.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.9ms\n","Speed: 3.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.5ms\n","Speed: 3.4ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.1ms\n","Speed: 3.3ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.2ms\n","Speed: 7.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 13.2ms\n","Speed: 3.1ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 13.0ms\n","Speed: 3.2ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 10.0ms\n","Speed: 3.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 10.6ms\n","Speed: 3.8ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.3ms\n","Speed: 3.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 10.3ms\n","Speed: 3.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.6ms\n","Speed: 3.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.8ms\n","Speed: 3.7ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.8ms\n","Speed: 3.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 13.5ms\n","Speed: 3.4ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 13.8ms\n","Speed: 3.1ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.8ms\n","Speed: 3.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 12.5ms\n","Speed: 4.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 24.2ms\n","Speed: 12.4ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.7ms\n","Speed: 3.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 11.7ms\n","Speed: 3.0ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 7.8ms\n","Speed: 3.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.0ms\n","Speed: 3.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 74.2ms\n","Speed: 3.6ms preprocess, 74.2ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 15.1ms\n","Speed: 7.6ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 18.4ms\n","Speed: 3.2ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.1ms\n","Speed: 2.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.2ms\n","Speed: 3.0ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.3ms\n","Speed: 3.4ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 8.2ms\n","Speed: 3.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 11.9ms\n","Speed: 9.3ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.0ms\n","Speed: 5.3ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 16.0ms\n","Speed: 3.3ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 8.7ms\n","Speed: 5.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.8ms\n","Speed: 3.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.3ms\n","Speed: 3.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 15.8ms\n","Speed: 5.1ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 14.7ms\n","Speed: 3.3ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 12.6ms\n","Speed: 3.1ms preprocess, 12.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.0ms\n","Speed: 3.1ms preprocess, 9.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 15.7ms\n","Speed: 8.3ms preprocess, 15.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 14.8ms\n","Speed: 3.0ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 13.7ms\n","Speed: 3.0ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.8ms\n","Speed: 2.8ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 10.7ms\n","Speed: 3.2ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 15.7ms\n","Speed: 4.9ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 12.7ms\n","Speed: 4.6ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 6.8ms\n","Speed: 2.6ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.7ms\n","Speed: 2.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 10.2ms\n","Speed: 3.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.0ms\n","Speed: 3.1ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.2ms\n","Speed: 3.2ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 11.3ms\n","Speed: 3.2ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 11.7ms\n","Speed: 4.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 29 persons, 7.6ms\n","Speed: 3.0ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 8.4ms\n","Speed: 3.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 28 persons, 7.3ms\n","Speed: 3.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 27 persons, 9.9ms\n","Speed: 3.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 8.1ms\n","Speed: 3.0ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 11.4ms\n","Speed: 4.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 10.1ms\n","Speed: 3.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 26 persons, 9.6ms\n","Speed: 4.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.8ms\n","Speed: 4.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.0ms\n","Speed: 3.2ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 9.6ms\n","Speed: 3.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.9ms\n","Speed: 4.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.0ms\n","Speed: 4.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.7ms\n","Speed: 2.7ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 13.5ms\n","Speed: 3.2ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 10.5ms\n","Speed: 3.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 9.7ms\n","Speed: 3.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 7.0ms\n","Speed: 3.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 7.3ms\n","Speed: 3.1ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 9.8ms\n","Speed: 3.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 9.9ms\n","Speed: 3.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.6ms\n","Speed: 3.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.7ms\n","Speed: 3.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 9.8ms\n","Speed: 3.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 10.4ms\n","Speed: 3.1ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 11.5ms\n","Speed: 3.1ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.9ms\n","Speed: 3.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.0ms\n","Speed: 3.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.3ms\n","Speed: 3.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.8ms\n","Speed: 3.4ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.0ms\n","Speed: 3.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 8.4ms\n","Speed: 3.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.7ms\n","Speed: 3.0ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.5ms\n","Speed: 3.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.1ms\n","Speed: 3.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 11.7ms\n","Speed: 3.7ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.0ms\n","Speed: 3.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 30.3ms\n","Speed: 3.4ms preprocess, 30.3ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 15.4ms\n","Speed: 3.9ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 10.2ms\n","Speed: 3.9ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.2ms\n","Speed: 3.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 12.0ms\n","Speed: 4.1ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 14.7ms\n","Speed: 3.9ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.1ms\n","Speed: 5.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.3ms\n","Speed: 3.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.1ms\n","Speed: 3.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 8.6ms\n","Speed: 3.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 7.3ms\n","Speed: 3.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 10.3ms\n","Speed: 4.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.2ms\n","Speed: 5.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.9ms\n","Speed: 3.4ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 19.9ms\n","Speed: 6.1ms preprocess, 19.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 12.8ms\n","Speed: 3.3ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 10.5ms\n","Speed: 3.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 8.1ms\n","Speed: 3.1ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 10.1ms\n","Speed: 3.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 7.7ms\n","Speed: 3.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 7.2ms\n","Speed: 3.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 6.7ms\n","Speed: 2.8ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 12.0ms\n","Speed: 3.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 10.9ms\n","Speed: 5.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 9.0ms\n","Speed: 2.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 10.2ms\n","Speed: 2.9ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 8.6ms\n","Speed: 3.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 7.2ms\n","Speed: 3.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 8.1ms\n","Speed: 3.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.5ms\n","Speed: 3.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.9ms\n","Speed: 4.0ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.0ms\n","Speed: 2.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 14.8ms\n","Speed: 3.9ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.6ms\n","Speed: 3.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 7.2ms\n","Speed: 6.0ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 7.2ms\n","Speed: 3.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 7.3ms\n","Speed: 3.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 11.7ms\n","Speed: 3.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.8ms\n","Speed: 3.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 9.9ms\n","Speed: 3.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 22 persons, 18.1ms\n","Speed: 3.0ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 11.4ms\n","Speed: 3.1ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 11.4ms\n","Speed: 3.2ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 11.5ms\n","Speed: 3.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 11.8ms\n","Speed: 3.3ms preprocess, 11.8ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 11.0ms\n","Speed: 3.3ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 17 persons, 10.7ms\n","Speed: 3.5ms preprocess, 10.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 18 persons, 12.0ms\n","Speed: 5.2ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 19 persons, 8.7ms\n","Speed: 4.0ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 20 persons, 9.2ms\n","Speed: 3.8ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 9.5ms\n","Speed: 3.5ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 19.9ms\n","Speed: 3.5ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 10.2ms\n","Speed: 3.1ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 14.1ms\n","Speed: 3.8ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 20.3ms\n","Speed: 4.8ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 21 persons, 14.1ms\n","Speed: 5.2ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 11.3ms\n","Speed: 3.0ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 13.7ms\n","Speed: 5.5ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 19.8ms\n","Speed: 3.0ms preprocess, 19.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 10.4ms\n","Speed: 3.8ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 20.4ms\n","Speed: 3.3ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 12.9ms\n","Speed: 3.0ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 11.4ms\n","Speed: 3.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 10.9ms\n","Speed: 8.9ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 23 persons, 21.1ms\n","Speed: 5.9ms preprocess, 21.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 15.3ms\n","Speed: 3.0ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 12.2ms\n","Speed: 3.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 9.6ms\n","Speed: 3.0ms preprocess, 9.6ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 8.9ms\n","Speed: 3.5ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 8.2ms\n","Speed: 6.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 24 persons, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 10.1ms\n","Speed: 3.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.7ms\n","Speed: 3.3ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 25 persons, 7.0ms\n","Speed: 2.9ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Video frame is empty\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aaR7ALdAOe7e","executionInfo":{"status":"ok","timestamp":1722506547360,"user_tz":-60,"elapsed":4,"user":{"displayName":"António Rodrigues","userId":"17923979113778682769"}}},"execution_count":6,"outputs":[]}]}